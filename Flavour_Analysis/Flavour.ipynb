{
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "name": "",
  "signature": "sha256:8be80b0b597bcb1150bbaee3dc4533055c1af780c3b6d105e6b16e6d082c509d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import numpy\n",
      "import scipy\n",
      "import matplotlib\n",
      "matplotlib.use('TkAgg')\n",
      "#import pylab\n",
      "import scipy.cluster.hierarchy as sch\n",
      "numpy.set_printoptions(threshold=numpy.nan)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fema_terms_molecules = pd.read_csv(\"./fema_terms_compounds2.csv\")\n",
      "fema_terms_molecules = fema_terms_molecules.replace('Not Available', np.nan)\n",
      "print(len(fema_terms_molecules))\n",
      "na_terms = fema_terms_molecules.isnull().sum()\n",
      "print(na_terms)\n",
      "fema_terms_molecules = fema_terms_molecules.replace('Not Available', np.nan).dropna()\n",
      "\n",
      "#count NA terms\n",
      "fema_terms_molecules.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2229\n",
        "pubchem_id               0\n",
        "fema_flavor_profile    600\n",
        "dtype: int64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>pubchem_id</th>\n",
        "      <th>fema_flavor_profile</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>47</td>\n",
        "      <td>Fruit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>58</td>\n",
        "      <td>Savory</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>70</td>\n",
        "      <td>Fruit</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>119</td>\n",
        "      <td>Savory</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>125</td>\n",
        "      <td>Nuts</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "   pubchem_id fema_flavor_profile\n",
        "1          47               Fruit\n",
        "4          58              Savory\n",
        "5          70               Fruit\n",
        "7         119              Savory\n",
        "8         125                Nuts"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fema_dict=dict(zip(list(fema_terms_molecules['pubchem_id']), list(fema_terms_molecules['fema_flavor_profile'])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fema_terms = []\n",
      "fema_length = []\n",
      "fema_cocc = []\n",
      "\n",
      "fft_list = []\n",
      "\n",
      "for key in fema_dict:\n",
      "    temp_list = []\n",
      "    #print key\n",
      "    temp_list = []\n",
      "    x = fema_dict[key]\n",
      "    #print x\n",
      "    y = x.replace(\", \",\",\")\n",
      "    #print y\n",
      "    y_list = y.replace(\"@\",\",\").split(',')\n",
      "    #print y_list\n",
      "    for term in y_list:\n",
      "        if(len(term.split(\" \"))<=2):\n",
      "            fema_terms.append(term)\n",
      "            temp_list.append(term)\n",
      "            \n",
      "    fft_list.append(','.join(temp_list))\n",
      "    \n",
      "    fema_length.append(len(y_list))\n",
      "    fema_cocc.append((\" \").join(x.split(', ')))\n",
      "\n",
      "fema_set = set(fema_terms)\n",
      "print(len(fema_set))\n",
      "fema_term_count = []\n",
      "with open('plot.csv', 'w+') as f:\n",
      "    c = csv.writer(f)\n",
      "    for word in fema_set:\n",
      "        fema_term_count.append(fema_terms.count(word))\n",
      "        x = fema_terms.count(word)\n",
      "        c.writerow([word] + [x])\n",
      "num_molecules = []\n",
      "fema_count_set = set(fema_length)\n",
      "for count in fema_count_set:\n",
      "    num_molecules.append(fema_length.count(count)) \n",
      "\n",
      "print(len(fft_list))\n",
      "#for i in fema_set:\n",
      "#    print i\n",
      "    \n",
      "#print num_molecules\n",
      "#print fema_count_set\n",
      "#fema_set\n",
      "#fema_count\n",
      "#fema_cocc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "248\n",
        "1629\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fema_terms_list= fema_terms_molecules['pubchem_id'].tolist()\n",
      "new_fema_terms_list = map(int, fema_terms_list)\n",
      "fema_flavour_list = fema_terms_molecules['fema_flavor_profile'].tolist()\n",
      "#new_fema_terms_list\n",
      "#fft_list\n",
      "#fema_flavour_list \n",
      "#fema_set = set(fema_flavour_list)\n",
      "#len(fema_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "420"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vector_list = []\n",
      "fema_list_new = list(fema_set)\n",
      "#print(fema_list_new)\n",
      "for i in fema_list_new:\n",
      "    mini_vector_list = []\n",
      "    for j in range(len(new_fema_terms_list)):\n",
      "        y = fft_list[j].split(\",\")\n",
      "        if(i in y):\n",
      "            mini_vector_list.append(1)\n",
      "        else:\n",
      "            mini_vector_list.append(0)\n",
      "    indices = [k for k, x in enumerate(mini_vector_list) if x == 1]\n",
      "    #print i, indices\n",
      "    vector_list.append(mini_vector_list)\n",
      "#print(vector_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "\n",
      "num_clusters = 32\n",
      "\n",
      "km = KMeans(n_clusters=num_clusters,max_iter=550,n_init=30)\n",
      "\n",
      "#%time km.fit(tfidf_matrix)\n",
      "%time km.fit(vector_list)\n",
      "labels1 = km.predict(vector_list)\n",
      "clusters = km.labels_.tolist()\n",
      "#print((sorted(clusters)))\n",
      "\n",
      "def duplicates(lst, item):\n",
      "    return [i for i, x in enumerate(lst) if x == item]\n",
      "\n",
      "new_dict = dict((x, duplicates(clusters, x)) for x in set(clusters) if clusters.count(x) >= 1)\n",
      "#for key in new_dict:\n",
      " #   print(key,len(new_dict[key]))\n",
      "#new_dict\n",
      "#print(clusters.count(5),clusters.count(0)+clusters.count(1)+clusters.count(2)+clusters.count(3)+clusters.count(4))\n",
      "#for i in range(num_clusters):\n",
      " #   print(i, clusters.count(i))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.53 s, sys: 8.43 s, total: 13 s\n",
        "Wall time: 3.34 s\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(40,41):\n",
      "    num_clusters = i\n",
      "\n",
      "    km = KMeans(n_clusters=num_clusters,max_iter=550,n_init=30)\n",
      "\n",
      "    #%time km.fit(tfidf_matrix)\n",
      "    %time km.fit(vector_list)\n",
      "    labels1 = km.predict(vector_list)\n",
      "    cluster_labels = km.fit_predict(vector_list)\n",
      "    clusters = km.labels_.tolist()\n",
      "    #print((sorted(clusters)))\n",
      "\n",
      "    def duplicates(lst, item):\n",
      "        return [i for i, x in enumerate(lst) if x == item]\n",
      "\n",
      "    new_dict = dict((x, duplicates(clusters, x)) for x in set(clusters) if clusters.count(x) >= 1)\n",
      "    clusters_diff = []\n",
      "    cluster_indices = []\n",
      "    for i in new_dict:\n",
      "        x = new_dict[i]\n",
      "        flavours = []\n",
      "        flavour_indices = []\n",
      "        for j in x:\n",
      "            flavours.append(fema_list_new[j])\n",
      "            flavour_indices.append(j)\n",
      "        print(\"cluster: \",i,\" \",flavours,len(flavours))\n",
      "        print \"\"\n",
      "        clusters_diff.append(flavours)\n",
      "        cluster_indices.append(flavour_indices)\n",
      "    #cluster_labels = clusterer.fit_predict(X)\n",
      "\n",
      "    # The silhouette_score gives the average value for all the samples.\n",
      "    # This gives a perspective into the density and separation of the formed\n",
      "    # clusters\n",
      "    #silhouette_avg = silhouette_score(vector_list, cluster_labels)\n",
      "    #print(\"For n_clusters =\", n_clusters,\n",
      "     #     \"The average silhouette_score is :\", silhouette_avg)\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 5.79 s, sys: 11.4 s, total: 17.2 s\n",
        "Wall time: 5.1 s\n",
        "('cluster: ', 0, ' ', ['Pear'], 1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "('cluster: ', 1, ' ', ['Fir', 'Leaf', 'Aromatic', 'Hay', 'Wet', 'Melon', 'Beeswax', 'Fabric', 'Yeast', 'Red Fruit', 'Camomile', 'Brandy', 'Green Bean', 'Burnt', 'Spearmint', 'Coriander', 'Waxy', 'Bell Pepper', 'Thyme', 'Potato', 'Apricot', 'Plum', 'Hazelnut', 'Coconut', 'Candy', 'Cat', 'Cooked', 'Toasted Nut', 'Pine', 'Grass', 'Green Fruit', 'Wine', 'Rubber', 'Penetrating', 'Roasted Corn', 'Green Pepper', 'Arise', 'Sharp', 'Iron Scorch', 'Peanut Butter', 'Lemon', 'Harsh', 'Cooked Meat', 'Cotton Candy', 'Licorice', 'Thiamin', 'Walnut', 'Mandarin', 'Geranium', 'Stable', 'Roasted Meat', 'Roasted Onion', 'Cedarwood', 'Meat Broth', 'Wet Hay', 'Gravy', 'Acid', 'Rum', 'Lily', 'Fennel', 'Vinegar', 'Eucalyptol', 'Heat', 'Warm', 'Watermelon', 'Cereal', 'Hot Milk', 'Raspberry', 'Dull', 'Cooked potato', 'Malt', 'Silage', 'Berry', 'Polish', 'Tallow', 'Baked', 'Fruity', 'Fragrant', 'Green Apple', 'Marshmallow', 'Strawberry', 'Fish', 'Almond', 'Lavender', 'Blue Cheese', 'Roast Beef', 'Paper', 'Pastry', 'Violet', 'Nutmeg', 'Durian', 'Burnt Sugar', 'Sweat', 'Grape', 'Anise', 'Roasted Garlic', 'Tomato Leaf', 'Foxy', 'Horseradish', 'Brown Sugar', 'Wax', 'Basil', 'Linoleum', 'Fusel Oil', 'Leek', 'Boiled Apple', 'Fermented', 'Toasted Cereal', 'Greenery', 'Pepper', 'Apple ', 'Petrol', 'Curry', 'Rhubarb', 'Roasted Nut', 'Pleasant', 'Deep Fried', 'Cucumber', 'Moss', 'Peanut', 'Dust', 'Balsamic', 'Bread', 'Green Leaf', 'Mouthfeel', 'Prune', 'Asparagus', 'Baked Potatoes', 'Stinging Nettle', 'Caramel', 'Cinnamon', 'Fried', 'Overripe Fruit', 'Lilac', 'Creamy', 'Radish', 'Cognac', 'Glue', 'Oxidized', 'Tomato', 'Clove', 'Almonds', 'Alcohol', 'Fruit Gum', 'Cherry', 'Fish Oil', 'Celery', 'Orange', 'Hop', 'Pyridine', 'Ester', 'Truffle', 'Orris', 'Lactone', 'Dry Fish', 'Mothball', 'Solvent', 'Mustard', 'Mushroom', 'Lettuce', 'Apple Peel', 'Bitter', 'Astringent', 'Jasmine', 'Leather', 'Vegetable', 'Cut Grass', 'Carbide', 'Vanilla', 'Seaweed', 'Kiwi', 'Tropical Fruit', 'Organic', 'Meat', 'Wet Earth', 'Lemon Peel', 'Coffee', 'Peppermint', 'Orange Peel', 'Soup', 'Mango', 'Umami', 'Camphor', 'Unripe Banana', 'Roasted Pepper', 'Passion Fruit', 'Bitter Almond', 'Fatty', 'Dill', 'Burnt Matches', 'Box Tree', 'Roasted Bread', 'Straw', 'Mold', 'Boiled Vegetable', 'Cresol', 'Caraway', 'Mocha', 'Dandelion', 'Boiled Cherries', 'Wet Wool', 'Putty', 'Roasted', 'Soy', 'Bread Crust', 'Cotton', 'Cooked Nut', 'Maple'], 208)\n",
        "\n",
        "('cluster: ', 2, ' ', ['Fruit'], 1)\n",
        "\n",
        "('cluster: ', 3, ' ', ['Green'], 1)\n",
        "\n",
        "('cluster: ', 4, ' ', ['Savory'], 1)\n",
        "\n",
        "('cluster: ', 5, ' ', ['Floral'], 1)\n",
        "\n",
        "('cluster: ', 6, ' ', ['Cool'], 1)\n",
        "\n",
        "('cluster: ', 7, ' ', ['Spice'], 1)\n",
        "\n",
        "('cluster: ', 8, ' ', ['Fat'], 1)\n",
        "\n",
        "('cluster: ', 9, ' ', ['Pungent'], 1)\n",
        "\n",
        "('cluster: ', 10, ' ', ['Garlic'], 1)\n",
        "\n",
        "('cluster: ', 11, ' ', ['Cocoa'], 1)\n",
        "\n",
        "('cluster: ', 12, ' ', ['Must'], 1)\n",
        "\n",
        "('cluster: ', 13, ' ', ['Popcorn'], 1)\n",
        "\n",
        "('cluster: ', 14, ' ', ['Onion'], 1)\n",
        "\n",
        "('cluster: ', 15, ' ', ['Dairy'], 1)\n",
        "\n",
        "('cluster: ', 16, ' ', ['Pineapple'], 1)\n",
        "\n",
        "('cluster: ', 17, ' ', ['Sulfur'], 1)\n",
        "\n",
        "('cluster: ', 18, ' ', ['Oil'], 1)\n",
        "\n",
        "('cluster: ', 19, ' ', ['Nut'], 1)\n",
        "\n",
        "('cluster: ', 20, ' ', ['Grapefruit', 'Black Currant'], 2)\n",
        "\n",
        "('cluster: ', 21, ' ', ['Citrus'], 1)\n",
        "\n",
        "('cluster: ', 22, ' ', ['Honey'], 1)\n",
        "\n",
        "('cluster: ', 23, ' ', ['Apple'], 1)\n",
        "\n",
        "('cluster: ', 24, ' ', ['Herb'], 1)\n",
        "\n",
        "('cluster: ', 25, ' ', ['Earth'], 1)\n",
        "\n",
        "('cluster: ', 26, ' ', ['Roast'], 1)\n",
        "\n",
        "('cluster: ', 27, ' ', ['Rose'], 1)\n",
        "\n",
        "('cluster: ', 28, ' ', ['Peach'], 1)\n",
        "\n",
        "('cluster: ', 29, ' ', ['Fresh'], 1)\n",
        "\n",
        "('cluster: ', 30, ' ', ['Butter'], 1)\n",
        "\n",
        "('cluster: ', 31, ' ', ['Mint'], 1)\n",
        "\n",
        "('cluster: ', 32, ' ', ['Nuts'], 1)\n",
        "\n",
        "('cluster: ', 33, ' ', ['Cabbage'], 1)\n",
        "\n",
        "('cluster: ', 34, ' ', ['Wood'], 1)\n",
        "\n",
        "('cluster: ', 35, ' ', ['Phenol'], 1)\n",
        "\n",
        "('cluster: ', 36, ' ', ['Flower'], 1)\n",
        "\n",
        "('cluster: ', 37, ' ', ['Cheese'], 1)\n",
        "\n",
        "('cluster: ', 38, ' ', ['Banana'], 1)\n",
        "\n",
        "('cluster: ', 39, ' ', ['Sour'], 1)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters_diff = []\n",
      "for i in new_dict:\n",
      "    x = new_dict[i]\n",
      "    flavours = []\n",
      "    for j in x:\n",
      "        flavours.append(fema_list_new[j])\n",
      "    #print(\"cluster: \",i,\" \",flavours,len(flavours))\n",
      "    #print \"\"\n",
      "    clusters_diff.append(flavours)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fema_terms = []\n",
      "fema_length = []\n",
      "fema_cocc = []\n",
      "new_fema_cocc = []\n",
      "fft_list = []\n",
      "\n",
      "for key in fema_dict:\n",
      "    temp_list = []\n",
      "    #print key\n",
      "    temp_list = []\n",
      "    x = fema_dict[key]\n",
      "    #print x\n",
      "    y = x.replace(\", \",\",\")\n",
      "    #print y\n",
      "    y_list = y.replace(\"@\",\",\").split(',')\n",
      "    #print y_list\n",
      "    for term in y_list:\n",
      "        if(len(term.split(\" \"))<=2):\n",
      "            fema_terms.append(term)\n",
      "            temp_list.append(term)\n",
      "            \n",
      "    fft_list.append(','.join(temp_list))\n",
      "    \n",
      "    fema_length.append(len(y_list))\n",
      "    fema_cocc.append((\" \").join(x.split(', ')))\n",
      "    new_fema_cocc.append(temp_list)\n",
      "    \n",
      "fema_set = set(fema_terms)\n",
      "print(len(fema_set))\n",
      "fema_term_count = []\n",
      "with open('plot.csv', 'w+') as f:\n",
      "    c = csv.writer(f)\n",
      "    for word in fema_set:\n",
      "        fema_term_count.append(fema_terms.count(word))\n",
      "        x = fema_terms.count(word)\n",
      "        c.writerow([word] + [x])\n",
      "num_molecules = []\n",
      "fema_count_set = set(fema_length)\n",
      "for count in fema_count_set:\n",
      "    num_molecules.append(fema_length.count(count)) \n",
      "\n",
      "print(len(fft_list))\n",
      "#for i in fema_set:\n",
      "#    print i\n",
      "    \n",
      "#print num_molecules\n",
      "#print fema_count_set\n",
      "#fema_set\n",
      "#fema_count\n",
      "#print((new_fema_cocc))\n",
      "full_list = []\n",
      "for i in new_fema_cocc:\n",
      "    full_list.extend(i)\n",
      "#print(len(full_list))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "248\n",
        "1629\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "import itertools\n",
      "from collections import Counter\n",
      "ranked_list = []\n",
      "import numpy\n",
      "import itertools\n",
      "from collections import Counter\n",
      "ranked_list = []\n",
      "\n",
      "varnames = tuple(sorted(set(itertools.chain(*new_fema_cocc))))\n",
      "expanded = [tuple(itertools.combinations(d, 2)) for d in new_fema_cocc]\n",
      "expanded = itertools.chain(*expanded)\n",
      "expanded = [tuple(sorted(d)) for d in expanded]\n",
      "c = Counter(expanded)\n",
      "table = numpy.zeros((len(varnames),len(varnames)), dtype=int)\n",
      "normalised_ranked_list = []\n",
      "\n",
      "for i, v1 in enumerate(varnames):\n",
      "    ranked_list = []\n",
      "    for j, v2 in enumerate(varnames):        \n",
      "        #j = j + i \n",
      "        if(c[v1,v2]!=0):\n",
      "            ranked_list.append( (float(c[v1,v2])/float(max(full_list.count(varnames[i]),full_list.count(varnames[j])))))\n",
      "            table[i, j] = float(c[v1,v2])/float(max(full_list.count(varnames[i]),full_list.count(varnames[j])))\n",
      "            table[j, i] = float(c[v1,v2])/float(max(full_list.count(varnames[i]),full_list.count(varnames[j])))\n",
      "        else:\n",
      "            ranked_list.append(0)\n",
      "    normalised_ranked_list.append(ranked_list)\n",
      "#pd.DataFrame(table)\n",
      "\n",
      "score = 0\n",
      "actual_score = 0\n",
      "for i,v1 in enumerate(varnames):\n",
      "    for j,v2 in enumerate(varnames):\n",
      "        flag = 0\n",
      "        for list_index in cluster_indices:\n",
      "            if(normalised_ranked_list[i][j]!=0):\n",
      "                if(i in list_index and j in list_index):\n",
      "                    score = score + normalised_ranked_list[i][j]\n",
      "                    flag = 1\n",
      "                    break\n",
      "                else:\n",
      "                    flag = 0\n",
      "        actual_score = actual_score + normalised_ranked_list[i][j] \n",
      "        if(flag==0):\n",
      "            score = score - normalised_ranked_list[i][j]\n",
      "print score \n",
      "actual_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "42.5121970928\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "118.95778101150835"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmeans_sim = 42.5121970928\n",
      "spherical_kmeans_sim = 23."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jaccard_similarity_cluster = []\n",
      "hamann_similarity_cluster = []\n",
      "jac_sim = 0\n",
      "ham_sim = 0\n",
      "max_jac_sim = 0\n",
      "max_ham_sim = 0\n",
      "min_jac_sim = 0\n",
      "min_ham_sim = 0\n",
      "for cluster in cluster_indices:\n",
      "    jac_sim = 0\n",
      "    ham_sim = 0\n",
      "    max_jac_sim = 0\n",
      "    max_ham_sim = 0\n",
      "    min_jac_sim = 0\n",
      "    min_ham_sim = 0\n",
      "    for i in range(len(cluster)):\n",
      "        for j in range(i+1,len(cluster)):\n",
      "            jac_sim = jac_sim + float(c[varnames[i],varnames[j]])/float((full_list.count(varnames[i])+full_list.count(varnames[j])) - float(c[varnames[i],varnames[j]]))\n",
      "            max_jac_sim = max_jac_sim + 248 / 248 + 248 - 248\n",
      "            min_jac_sim = min_jac_sim + 0\n",
      "            numerator = (float(c[varnames[i],varnames[j]]) + (float(248) - float(c[varnames[i],varnames[j]])) - ((full_list.count(varnames[i])) - float(c[varnames[i],varnames[j]])) - (full_list.count(varnames[j]) - float(c[varnames[i],varnames[j]])))\n",
      "            denominator = (float(c[varnames[i],varnames[j]]) + (float(248) - float(c[varnames[i],varnames[j]])) + ((full_list.count(varnames[i])) - float(c[varnames[i],varnames[j]])) + (full_list.count(varnames[j]) - float(c[varnames[i],varnames[j]])))\n",
      "            ham_sim = ham_sim + float(numerator)/float(denominator)\n",
      "            max_ham_sim = max_ham_sim + 248/248\n",
      "            min_ham_sim = min_ham_sim + 0 \n",
      "    jaccard_similarity_cluster.append(jac_sim)\n",
      "    hamann_similarity_cluster.append(ham_sim)\n",
      "jaccard_similarity_cluster "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[0,\n",
        " 72.52129309706156,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0.0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from coclust.clustering.spherical_kmeans import SphericalKmeans"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_clusters = 25\n",
      "\n",
      "km1 = SphericalKmeans(n_clusters=num_clusters,max_iter=100,n_init=1)\n",
      "\n",
      "#%time km.fit(tfidf_matrix)\n",
      "%time km1.fit(np.array(vector_list))\n",
      "#labels2 = km1.predict(vector_list)\n",
      "clusters2 = km1.labels_\n",
      "#print((sorted(clusters)))\n",
      "\n",
      "def duplicates(lst, item):\n",
      "    return [i for i, x in enumerate(lst) if x == item]\n",
      "\n",
      "new_dict = dict((x, duplicates(clusters2, x)) for x in set(clusters2) if clusters2.count(x) >= 1)\n",
      "clusters_diff = []\n",
      "cluster_indices = []\n",
      "for i in new_dict:\n",
      "    x = new_dict[i]\n",
      "    flavours = []\n",
      "    flavour_indices = []\n",
      "    for j in x:\n",
      "        flavours.append(fema_list_new[j])\n",
      "        flavour_indices.append(j)\n",
      "    print(\"cluster: \",i,\" \",flavours,len(flavours))\n",
      "    print \"\"\n",
      "    clusters_diff.append(flavours)\n",
      "    cluster_indices.append(flavour_indices)\n",
      "    #cluster_labels = clusterer.fit_predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " == New init == \n",
        "('iteration:', 0)\n",
        "79.3644520129\n",
        "('iteration:', 1)\n",
        "84.0572362227\n",
        "('iteration:', 2)\n",
        "86.0409040848\n",
        "('iteration:', 3)\n",
        "86.5202595309\n",
        "('iteration:', 4)\n",
        "86.7632374794\n",
        "('iteration:', 5)\n",
        "87.0106012591\n",
        "('iteration:', 6)\n",
        "CPU times: user 100 ms, sys: 4 ms, total: 104 ms\n",
        "Wall time: 195 ms\n",
        "('cluster: ', 0, ' ', ['Iron Scorch', 'Peanut Butter', 'Fennel', 'Foxy', 'Basil', 'Bitter', 'Peppermint', 'Dill', 'Caraway'], 9)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "('cluster: ', 1, ' ', ['Citrus', 'Lily', 'Warm', 'Polish', 'Burnt Sugar', 'Overripe Fruit', 'Fruit Gum', 'Cherry', 'Apple Peel', 'Astringent', 'Camphor', 'Roasted Pepper'], 12)\n",
        "\n",
        "('cluster: ', 2, ' ', ['Cat', 'Grass', 'Rubber', 'Cotton Candy', 'Silage', 'Fruity', 'Nutmeg', 'Toasted Cereal', 'Dry Fish', 'Soup'], 10)\n",
        "\n",
        "('cluster: ', 3, ' ', ['Pine', 'Cooked Meat', 'Licorice', 'Baked', 'Nut', 'Orange', 'Truffle', 'Cut Grass', 'Coffee'], 9)\n",
        "\n",
        "('cluster: ', 4, ' ', ['Mint', 'Fabric', 'Wine', 'Cool', 'Dull', 'Fish', 'Durian', 'Jasmine', 'Cotton'], 9)\n",
        "\n",
        "('cluster: ', 5, ' ', ['Yeast', 'Fat', 'Coriander', 'Bell Pepper', 'Honey', 'Grapefruit', 'Vinegar', 'Strawberry', 'Horseradish', 'Boiled Apple', 'Mouthfeel', 'Fried', 'Vegetable', 'Umami', 'Box Tree'], 15)\n",
        "\n",
        "('cluster: ', 6, ' ', ['Beeswax', 'Apricot', 'Coconut', 'Malt', 'Apple ', 'Curry', 'Rhubarb', 'Roasted Nut', 'Deep Fried', 'Apple', 'Meat'], 11)\n",
        "\n",
        "('cluster: ', 7, ' ', ['Fir', 'Hot Milk', 'Marshmallow', 'Linoleum', 'Greenery', 'Pepper', 'Cocoa', 'Passion Fruit', 'Mold', 'Roasted'], 10)\n",
        "\n",
        "('cluster: ', 8, ' ', ['Potato', 'Walnut', 'Lavender', 'Brown Sugar', 'Butter', 'Unripe Banana', 'Bitter Almond'], 7)\n",
        "\n",
        "('cluster: ', 9, ' ', ['Leaf', 'Aromatic', 'Melon', 'Hazelnut', 'Green Fruit', 'Rose', 'Roasted Meat', 'Rum', 'Green Apple', 'Sweat', 'Anise', 'Organic', 'Maple'], 13)\n",
        "\n",
        "('cluster: ', 10, ' ', ['Flower', 'Savory', 'Roasted Onion', 'Cedarwood', 'Violet', 'Fusel Oil', 'Prune', 'Creamy', 'Lettuce'], 9)\n",
        "\n",
        "('cluster: ', 11, ' ', ['Burnt', 'Blue Cheese', 'Grape', 'Tomato Leaf', 'Baked Potatoes', 'Tomato', 'Lactone', 'Tropical Fruit', 'Lemon Peel'], 9)\n",
        "\n",
        "('cluster: ', 12, ' ', ['Red Fruit', 'Penetrating', 'Green Pepper', 'Arise', 'Bread', 'Cinnamon', 'Wood', 'Ester', 'Orris', 'Cresol', 'Mocha'], 11)\n",
        "\n",
        "('cluster: ', 13, ' ', ['Hay', 'Peach', 'Herb', 'Black Currant', 'Berry', 'Roasted Garlic', 'Wax', 'Petrol', 'Oxidized', 'Celery', 'Vanilla', 'Straw'], 12)\n",
        "\n",
        "('cluster: ', 14, ' ', ['Thiamin', 'Pear', 'Garlic', 'Balsamic', 'Sour', 'Asparagus', 'Radish', 'Glue', 'Wet Earth', 'Boiled Vegetable'], 10)\n",
        "\n",
        "('cluster: ', 15, ' ', ['Camomile', 'Brandy', 'Spearmint', 'Waxy', 'Watermelon', 'Cereal', 'Pastry', 'Dust', 'Green Leaf', 'Mothball', 'Fruit', 'Fatty', 'Wet Wool'], 13)\n",
        "\n",
        "('cluster: ', 16, ' ', ['Pineapple', 'Sulfur', 'Heat', 'Must', 'Cooked potato', 'Fragrant', 'Paper', 'Dairy', 'Pyridine', 'Fresh'], 10)\n",
        "\n",
        "('cluster: ', 17, ' ', ['Plum', 'Candy', 'Almond', 'Alcohol'], 4)\n",
        "\n",
        "('cluster: ', 18, ' ', ['Lemon', 'Meat Broth', 'Acid', 'Leek', 'Pleasant', 'Onion', 'Stinging Nettle', 'Floral', 'Cognac', 'Cabbage', 'Seaweed', 'Oil'], 12)\n",
        "\n",
        "('cluster: ', 19, ' ', ['Green Bean', 'Toasted Nut', 'Sharp', 'Harsh', 'Pungent', 'Earth', 'Banana', 'Solvent', 'Putty'], 9)\n",
        "\n",
        "('cluster: ', 20, ' ', ['Thyme', 'Mandarin', 'Geranium', 'Wet Hay', 'Roast Beef', 'Phenol', 'Fermented', 'Lilac', 'Cooked Nut'], 9)\n",
        "\n",
        "('cluster: ', 21, ' ', ['Cooked', 'Stable', 'Cucumber', 'Caramel', 'Leather', 'Bread Crust'], 6)\n",
        "\n",
        "('cluster: ', 22, ' ', ['Spice', 'Roasted Corn', 'Raspberry', 'Peanut', 'Roast', 'Almonds', 'Hop', 'Mustard', 'Carbide', 'Popcorn', 'Burnt Matches', 'Soy'], 12)\n",
        "\n",
        "('cluster: ', 23, ' ', ['Wet', 'Gravy', 'Green', 'Kiwi', 'Orange Peel'], 5)\n",
        "\n",
        "('cluster: ', 24, ' ', ['Nuts', 'Eucalyptol', 'Tallow', 'Moss', 'Cheese', 'Clove', 'Fish Oil', 'Mushroom', 'Mango', 'Roasted Bread', 'Dandelion', 'Boiled Cherries'], 12)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "score = 0\n",
      "actual_score = 0\n",
      "for i,v1 in enumerate(varnames):\n",
      "    for j,v2 in enumerate(varnames):\n",
      "        flag = 0\n",
      "        for list_index in cluster_indices:\n",
      "            if(normalised_ranked_list[i][j]!=0):\n",
      "                if(i in list_index and j in list_index):\n",
      "                    score = score + normalised_ranked_list[i][j]\n",
      "                    flag = 1\n",
      "                    break\n",
      "                else:\n",
      "                    flag = 0\n",
      "        actual_score = actual_score + normalised_ranked_list[i][j] \n",
      "        if(flag==0):\n",
      "            score = score - normalised_ranked_list[i][j]\n",
      "print score \n",
      "actual_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-109.091078052\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "118.95778101150835"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jaccard_similarity_cluster = []\n",
      "hamann_similarity_cluster = []\n",
      "jac_sim = 0\n",
      "ham_sim = 0\n",
      "max_jac_sim = 0\n",
      "max_ham_sim = 0\n",
      "min_jac_sim = 0\n",
      "min_ham_sim = 0\n",
      "for cluster in cluster_indices:\n",
      "    jac_sim = 0\n",
      "    ham_sim = 0\n",
      "    max_jac_sim = 0\n",
      "    max_ham_sim = 0\n",
      "    min_jac_sim = 0\n",
      "    min_ham_sim = 0\n",
      "    for i in range(len(cluster)):\n",
      "        for j in range(i+1,len(cluster)):\n",
      "            jac_sim = jac_sim + float(c[varnames[i],varnames[j]])/float((full_list.count(varnames[i])+full_list.count(varnames[j])) - float(c[varnames[i],varnames[j]]))\n",
      "            max_jac_sim = max_jac_sim + 248 / 248 + 248 - 248\n",
      "            min_jac_sim = min_jac_sim + 0\n",
      "            numerator = (float(c[varnames[i],varnames[j]]) + (float(248) - float(c[varnames[i],varnames[j]])) - ((full_list.count(varnames[i])) - float(c[varnames[i],varnames[j]])) - (full_list.count(varnames[j]) - float(c[varnames[i],varnames[j]])))\n",
      "            denominator = (float(c[varnames[i],varnames[j]]) + (float(248) - float(c[varnames[i],varnames[j]])) + ((full_list.count(varnames[i])) - float(c[varnames[i],varnames[j]])) + (full_list.count(varnames[j]) - float(c[varnames[i],varnames[j]])))\n",
      "            ham_sim = ham_sim + float(numerator)/float(denominator)\n",
      "            max_ham_sim = max_ham_sim + 248/248\n",
      "            min_ham_sim = min_ham_sim + 0 \n",
      "    jaccard_similarity_cluster.append(jac_sim)\n",
      "    manhattan_similarity_cluster.append(ham_sim)\n",
      "jaccard_similarity_cluster \n",
      "manhattan_similarity_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[32.7754851871755,\n",
        " 61.27713398122375,\n",
        " 41.292034785191575,\n",
        " 32.7754851871755,\n",
        " 32.7754851871755,\n",
        " 98.54177481036592,\n",
        " 50.792584383207654,\n",
        " 41.292034785191575,\n",
        " 19.08107330430232,\n",
        " 72.74568357923977,\n",
        " 32.7754851871755,\n",
        " 32.7754851871755,\n",
        " 50.792584383207654,\n",
        " 61.27713398122375,\n",
        " 41.292034785191575,\n",
        " 72.74568357923977,\n",
        " 41.292034785191575,\n",
        " 5.696210390427753,\n",
        " 61.27713398122375,\n",
        " 32.7754851871755,\n",
        " 32.7754851871755,\n",
        " 13.446738764034372,\n",
        " 61.27713398122375,\n",
        " 9.394301250914284,\n",
        " 61.27713398122375]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}